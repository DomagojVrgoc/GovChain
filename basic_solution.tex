% !TEX root = GovChain.tex

In this section we describe a basic infrastructure for publishing government data that allows anyone with a single data entry to challenge the veracity of the data in case it was manipulated. We also provide a simple protocol that enables us to increase the trust of the general public in the data provided by the government. We achieve both of these objective without modifying the way that the government currently publishes or stores their data. We start by recapping basic cryptographic primitives we will be using in the remainder of this paper.

\medskip
\noindent{\bf Cryptographic primitives.} The first cryptographic primitive we will be using is that of {\em cryptographic (digital) signature}. Roughly, one can view the digital signature protocol as consisting of the following three components:
\begin{itemize}
\item A pair $(\sk,\pk)$, where $\sk$ is the secret key known only to a user, and used to generate signatures, and $\pk$ is the public key is given to everyone in order to verify that a message's signature was indeed signed by the owner of the secret key $\sk$.
\item The method $\sign(\sk,\m)$, allowing a secret-key holder to sign the document data. 
\item The method $\verify(\pk,\m,\mathit{sig})$ that allows anyone to verify if $\mathit{sig}$ is a valid signature of the document $\m$ by the entity corresponding to the public key $\pk$.
\end{itemize}
The signature protocol is required to be sound. This means that it verifies correctly, in a sense that $\verify(\pk,m,\sign(\sk,m))$ is always true, and that signatures are unforgeable without the secret key $\sk$. There are many digital signature schemes currently in use, for more details we refer the reader to \cite{KatzLindell2014}. We also point out that a large number of governments have adopted digital signatures as standard, mandatory procedures.

The second primitive we recall is that of {\em cryptographic hash functions}. Roughly speaking, a cryptographic hash function is any function $h$ that takes as input an arbitrary sized document, and produces a fixed size output, can be efficiently computable, and satisfies the following two properties:
\begin{itemize}
\item {\em Hiding.} This means that for any given input $x$, it is infeasible to compute $x$ with knowledge of $h(x)$ only.\footnote{Strictly speaking, this also includes a random number $r$ coming from a distribution with high min-entropy, and being given $h(r||x)$ instead of $h(x)$.}
\item {\em Second preimage resistance.} Given an input $x_1$, it is unfeasible to find a different input $x_2$ such that $h(x_1)=h(x_2)$.
%\item {\em Collision resistance.} It is infeasible to efficiently find two different inputs $x$ and $y$, such that $h(x)=h(y)$.
\end{itemize}
The output of a hash function is called a hash value, or simply a hash. Notice that the hiding property of the hash function allows us to use $h(x)$ as a secure digest of our document $x$, since we can not reconstruct $x$ from $h(x)$ alone, and the value $h(x)$ is of fixed size, even for documents $x$ whose size is in TBs %\francisco{This is true but lacks some important properties of a secure encryption, maybe change the word encryption here?}. 
On the other hand, second preimage resistance ensures that in order to prove to someone who has only $h(x)$ that we have $x$, we need to provide said $x$. 

There are a number of cryptographic hash functions currently in use. To the date of this writing, most protocols adopt the NIST-approved Secure Hash Algorithms\cite{sha_standard}, which include SHA-256 and SHA-512 from the SHA-2 family, but other hash functions are considered equally secure and even more efficient. We highlight the BLAKE2 algorithm, released after the SHA-3 competition, which is more secure and faster than SHA-1 and SHA-2. In fact, on most common hardware settings, it is the fastest secure hash function available today, becoming the most popular non-NIST-standard hash algorithm, supported by major cryptographic libraries. For a more detailed treatment of cryptographic hash functions we refer the reader to \cite{sha_standard,aumasson,sha3zoo,bitcoinbook}. %\francisco{Took the liberty of changing this paragraph (from ``To the day...'' on) and adding some references. Feel free to come back to previous versions}

%%%OLD:
%\medskip
%\noindent{\bf Hash lists and Merkle trees.} 
%Let $h$ be a fixed cryptographic hash function. A hash list is an ordered list of data $[d_1,d_2,\dots, d_k]$ such that every element of the list contains the hash value of the previous element, \ie $h(d_1)\in d_2$. In a hash list, modifying the hash value of an element affects the hash values of all succesive nodes, and because of the second preimage resistant of $h$, it is unfeasible to replace an element of the list without having to update the list. Therefore, if the last value of the list is permanently monitored, there is virtually no way of modifying an element of the list while keeping the structure of hash list and not being detected. This is one of the core ideas behind Bitcoin's protocol \cite{whitepaper}, but it has been used widely in a number of precedent applications. \francisco{An actual example from chilean banks follows. Sometimes a PRNG instead of a hash function is used, but it still applies. If you think this example doesn't add to the discussion, just remove it.} For instance, to add an extra layer of security on transactions, some banks provide users small, offline devices that can store one 256-bit value $x$ and show the first six digits of $x$ to the user. Every four or five minutes, the device replaces $x$ with $h(x)$ for some (assumed public) hash function $h$. When a user is about to validate a transaction, the bank asks the six digits visible to the user, which proves possession of the said device with good probability. However, if an attacker knowing $h$ extracts the whole number once (or even only a sufficent amount of bits), they can predict all subsequent values displayed at the device, and successfully pass tests. This is why, in most scenarios, a hash list needs some source of randomness or interaction with some environment in order to be unpredictable.

\medskip
\noindent{\bf Hash lists and Merkle trees.} 
Let $h$ be a fixed cryptographic hash function. A {\em hash list} corresponding to (ordered) data items $d_1,d_2,\dots, d_k$ is a ordered list $[B_1,B_2,\ldots ,B_k]$ of elements (also called blocks), such that each $B_i$ contains the document $d_i$, and the value $h(B_{i-1})$. In a hash list, modifying the hash value of an element affects the hash values of all successive nodes, and because of the second preimage resistance of $h$, it is infeasible to replace an element of the list without having to update the list. Therefore, if the last value of the list is permanently monitored, there is virtually no way of modifying an element of the list while keeping the structure of hash list and not being detected. This is, in fact, one of the core ideas behind Bitcoin's protocol \cite{whitepaper}. We illustrate this idea in Figure \ref{hashlist}.


\begin{figure}
\resizebox{\columnwidth}{!}{
\centering
\begin {tikzpicture}[-latex ,auto ,node distance =1 cm and 1.8cm ,on grid, semithick, state/.style ={ rectangle , draw, minimum width =0.9 cm}]
\node[state] (0) {\begin{tabular}{c} $\bot$ \\ $d_1$ \end{tabular}};
\node[state] (1) [right =2.2cm of 0] {\begin{tabular}{c} $h(B_1)$ \\ $d_2$ \end{tabular}};
\node[state] (2) [right =2.5cm of 1] {\begin{tabular}{c} $h(B_2)$ \\ $d_3$ \end{tabular}};
\node[state] (3) [right =2.5cm of 2] {\begin{tabular}{c} $h(B_3)$ \\ $d_4$ \end{tabular}};
\node (etc) [right =of 3] {};

\node (1d) [above =20pt of 0]{$B_1$};
\node (2d) [above =20pt of 1]{$B_2$};
\node (3d) [above =20pt of 2]{$B_3$};
\node (4d) [above =20pt of 3]{$B_4$};

\path (1) edge (0);
\path (2) edge (1);
\path (3) edge (2);
\path (etc) edge [bend left = 0] node[below]{...}(3);

%\path (1d) edge [bend left = 0] (1);
%\path (2d) edge [bend left = 0] (2);
%\path (3d) edge [bend left = 0] (3);

\end{tikzpicture}
}
\caption{A hash list. A secure hash algorithm $h$ is used, and external data prevents predictability. Here we use $\bot$ to denote the default value used as the previous hash in the first block. The arrows in the list are symbolic, as the connection of a block $B_i$ with the block $B_{i-1}$ is actually established through the hash value $h(B_{i-1})$ stored in $B_i$.}
\label{hashlist}
\end{figure}

A {\em Merkle tree} is a data structure that displays one hash value linked to a set of documents, such that any modification on the underlying documents affects this global hash, called the Merkle root. In addition, any change to the Merkle root can be efficiently traced to the documents causing it. As a result, committing to a Merkle root obliges to commit to all documents included in the tree, which can be arbitrarily many. Given a set $d_1,\ldots ,d_k$ of documents, a Merkle tree corresponding to these documents, also denoted $MT(d_1,\ldots ,d_k)$, is constructed by grouping the elements in pairs (the final element being duplicated in case that $k$ is odd), computing their hash values, and creating a complete binary tree whose leaves are labelled with these hash values. Each node whose childern are labelled with $x_1$ and $x_2$ is then labelled with the value $h(x_1 || x_2)$, with $||$ denoting the concatenation of two hash values. We illustrate this construction in Figure \ref{merkle_fig}. To show that one particular document is in the Merkle tree, we need to provide a list of counterpart node labels (hashes) that appear on the path from the root of the tree to this document. What we mean by counterpart nodes, are the hash values of immediate siblings of each node on this path. For instance, to prove that the document $d_1$ belongs to the tree from Figure \ref{merkle_fig}, and we only know the hash value of the root node of this tree, we will need the document $d_1$, along with $x_2$ and $h(x_3||x_4)$. This way we can compute $x_1=h(d_1)$, the value $h(x_1||x_2)$, and the value of the root node. Since each path from the root of the Merkle tree to its leave is of the length $log(k)$, checking if a node belongs to a tree can be done efficiently. If we construct the tree by starting from a sorted list of documents (or their hashes), we can furthermore check  efficiently when a document does not belong to the tree with a certain root.

\begin{figure}
\resizebox{\columnwidth}{!}{
\centering
\begin {tikzpicture}[-latex ,auto ,node distance =1 cm and 1.8cm ,on grid, semithick, state/.style ={ rectangle , draw, minimum width =0.9 cm}]
% First floor 
\node[state] (d1) {$d_1$};
\node[state] (d2) [right =3cm of d1] {$d_2$};
\node[state] (d3) [right =3cm of d2] {$d_3$};
\node[state] (d4) [right =3cm of d3] {$d_4$};
% Second floor
\node[state] (h1) [above =1.25 of d1] {$x_1=h(d_1)$};
\node[state] (h2) [above =1.25 of d2] {$x_2=h(d_2)$};
\node[state] (h3) [above =1.25 of d3] {$x_3=h(d_3)$};
\node[state] (h4) [above =1.25 of d4] {$x_4=h(d_4)$};
% Third floor
\node[state] (h12) [above right =1.25 and 1.5 of h1] {$h(x_1 || x_2)$};
\node[state] (h34) [above right =1.25 and 1.5  of h3] {$h(x_3 || x_4)$};
% Root
\node[state] (root) [above right =1.25 and 3 of h12] {\small Root};

% First floor paths
\path (h1) edge node[left]{}(d1);
\path (h2) edge node[left]{}(d2);
\path (h3) edge node[left]{}(d3);
\path (h4) edge node[left]{}(d4);

% Second floor paths
\path (h12) edge node{} (h1);
\path (h12) edge node{} (h2);
\path (h34) edge node{} (h3);
\path (h34) edge node{} (h4);

% Third floor paths
\path (root) edge node{} (h12);
\path (root) edge node{} (h34);

\end{tikzpicture}
}
\caption{A Merkle tree with document list $[d_1,d_2,d_3,d_4]$ and secure hash function $h$. Here, the root contains the value $h(h(x_1||x_2)||h(x_3||h_4))$, depending on all previous nodes.}% In order to prove that $d_4$ is present on the tree, one needs to check the validity of the hash list $[x_4,h(x_3||x_4),\mathrm{root}]$ with knowledge of $x_3$ and $h(x_1||x_2)$ only.}
\label{merkle_fig}
\end{figure}

\medskip
\noindent{\bf Basic steps to gain trust.} Now that we understand the basic data structures that can guarantee immutability of the data, we can show how they can be used to provide compact certificates that no data was manipulated. The basic idea is quite simple: the government will keep on publishing their data as they do at the present, but at regular intervals, they will also publish a compact cryptographic digest of the new data. Assume that $d_1,d_2,\ldots ,d_k$ is the list of the documents published during one working day. Furthermore, assume that the order in which this list was published is made available in the day's digest. At the end of the day, the government will also create a Merkle tree $MT(d_1,\ldots ,d_k)$, whose leaves are the hash values of these documents, that is, the values $h(d_1),\ldots ,h(d_k)$. At this point, the government publishes $MT(d_1,\ldots ,d_k)$, together with the cryptographic signature of this data corresponding to the public key under which the government agreed to publish their data. The fact that the signature matches the data in the Merkle tree and the government's public key, allows us to easily verify that the data is legitimate, assuming that the government store their secret keys safely.

As explained above, anyone who witnesses the root of this Merkle tree (representing typically less than 100 bytes of information), can check whether the data corresponding to that single day was modified by downloading it in the sequence provided by the government, hashing it, and assembling a Merkle tree starting from these hashes. If the Merkle root published by the government does not match the one computed using this method, the verifier can know for certain that the data had been manipulated. It is assumed that the government makes it public knowledge which hashing algorithm and Merkle tree assembly they will be using.

Notice that if we want to be able to detect which particular documents were modified, we would have to store the entire Merkle tree. The size of this will be in tens of megabytes for a tree coding one million documents when using SHA-256 as the hash function, so one might argue that even this is a reasonable amount of storage needed to pinpoint which particular data had been manipulated. One can further restrict the amount of needed storage by storing fewer layers of the Merkle tree (\ie if one trims the original leaves the size will roughly half), but also losing the granularity at which manipulations can be detected. 
%For instance, if we store the tree up to the next to last level, we can check if one of the two adjacent documents in the list $d_1,\ldots ,d_n$ have been modified, but will not be able to say which one (Figure \ref{fig-trim}). 
For example, if we only store the root and its two children of the Merkle tree from Figure \ref{merkle_fig}, we can detect if there was a modification in the pair $d_1,d_2$, or the pair $d_3,d_4$, but we will not be able to say which of the two documents in the pair was modified.
Based on the volume of the published data, the government might also wish to publish these partial trees and sign them, in order to make it easier for a person to store this information.

It is possible to do better by utilizing the same idea that Bitcoin uses to store its blocks \cite{whitepaper}, and encode and/or publish the hash of the previous day's data in the current day's digest. That is, we can create a hash list of the Merkle roots published each day. This would mean that storing one day's Merkle root (or the entire tree) would not only assure that the data of that particular day can not be manipulated, but also, it would assure that the data in any of the days previous to this one could not be manipulated. Since each tree would also contain the hash value of the previous day's digest, one can simply follow this chain day after day, and see if any of the hash values do not match. 
This simple concept is illustrated in Figure \ref{fig-merkle-chain}. Notice that there are two structures that are connected here. On the bottom level, we have the Merkle tree constructed from the day's documents. The top level hash list is then constructed using the day's Merkle root as its data. That is, each element of this hash list contains the Merkle root of the current day, plus the hash value of the previous day's element. 

To summarize: in this approach, apart from the each day's data, the government would also publish the Merkle tree whose leaves are the hashes of the day's documents, plus a hash list built from the roots of these Merkle trees. In turn, each element of this list will contain the day's Merkle root as its data, plus the hash of the (entire) previous element in the list.

\begin{figure}
\centering
\begin {tikzpicture}[-latex ,auto ,node distance =1 cm and 2.5 cm ,on grid, semithick, state/.style ={ rectangle , draw, minimum width =0.9 cm}, substate/.style ={ rectangle , draw, minimum width =0.2 cm}]




\usetikzlibrary{shapes}
\node (x1) {};
\node (x2) [right = 2.7cm of x1]{};
\node (x3) [right = 2.7cm of x2]{};
\node (etc) [right = 1.8cm of x3]{};


\node[state] (r1) [below =of x1]{\scriptsize$\mathit{MR}_1$};
\draw [draw=black!50] ($(r1.south west) - (0.4,0.1cm)$) rectangle +(1.75cm, +1.2cm);
\node (h1) [above =15pt of r1]{$\bot$};
\node (bl1) [above =30pt of r1]{$B_1$};

\node[state] (r2) [right = 2.7 cm of r1]{\scriptsize$\mathit{MR}_2$};
\draw [draw=black!50] ($(r2.south west) - (0.4,0.1cm)$) rectangle +(1.75cm, +1.2cm);
\node (h2) [above =15pt of r2]{$h(B_1)$};
\node (bl2) [above =30pt of r2]{$B_2$};


\node[state] (r3) [right = 2.7cm of r2]{\scriptsize$\mathit{MR}_3$};
\draw [draw=black!50] ($(r3.south west) - (0.4,0.1cm)$) rectangle +(1.75cm, +1.2cm);
\node (h3) [above =15pt of r3]{$h(B_2)$};
\node (bl3) [above =30pt of r3]{$B_3$};


% First childs

\node[substate] (c11) [below left  = 0.9 of r1]{};
\node[substate] (c12) [below right = 0.9 of r1]{};
\node[substate] (c21) [below left  = 0.9 of r2]{};
\node[substate] (c22) [below right = 0.9 of r2]{};
\node[substate] (c31) [below left  = 0.9 of r3]{};
\node[substate] (c32) [below right = 0.9 of r3]{};

% Second childs

\node[substate] (c111) [below left  = 0.6 and 0.2 of c11]{};
\node[substate] (c112) [below right = 0.6 and 0.2 of c11]{};
\node[substate] (c121) [below left  = 0.6 and 0.2 of c12]{};
\node[substate] (c122) [below right = 0.6 and 0.2 of c12]{};


\node[substate] (c211) [below left  = 0.6 and 0.2 of c21]{};
\node[substate] (c212) [below right = 0.6 and 0.2 of c21]{};
\node[substate] (c221) [below left  = 0.6 and 0.2 of c22]{};
\node[substate] (c222) [below right = 0.6 and 0.2 of c22]{};


\node[substate] (c311) [below left  = 0.6 and 0.2 of c31]{};
\node[substate] (c312) [below right = 0.6 and 0.2 of c31]{};
\node[substate] (c321) [below left  = 0.6 and 0.2 of c32]{};
\node[substate] (c322) [below right = 0.6 and 0.2 of c32]{};

\node (etc111) [below = 0.3 of c111]{$\vdots$};
\node (etc112) [below = 0.3 of c112]{$\vdots$};

\node (etc121) [below = 0.3 of c121]{$\vdots$};
\node (etc122) [below = 0.3 of c122]{$\vdots$};

\node (etc21) [below = 0.9 of c21]{$\vdots$};
\node (etc22) [below = 0.9 of c22]{$\vdots$};
\node (etc31) [below = 0.9 of c31]{$\vdots$};
\node (etc32) [below = 0.9 of c32]{$\vdots$};

% Documents

\node (ghost1) [below left = 1.2 and 0.3 of c11]{};
\node (ghost2) [right = 1 of ghost1]{};
\node (ghost3) [right = 1 of ghost2]{};



\node (d1) [below left  = 0.8 and 0.3 of ghost1]{$d_1$};
\node (d2) [right = 0.5 of d1]{$d_2$};
\node (d3) [below left  = 0.8 and 0.25 of ghost2]{$d_3$};
\node (d4) [right = 0.5 of d3]{$d_4$};
\node (d5) [right = 0.5 of d4]{...};
\node (d6) [right = 0.5 of d5]{$d_k$};




%\path (r1) edge node {} (x1);
%\path (r2) edge node {} (x2);
%\path (r3) edge node {} (x3);
%\path (r3) edge node {} (x3);

%\path (x1) edge node {} (x2);
%\path (x2) edge node {} (x3);
%\path (x3) edge node {} (etc);

\path (r1) edge node {} (c11);
\path (r1) edge node {} (c12);
\path (r2) edge node {} (c21);
\path (r2) edge node {} (c22);
\path (r3) edge node {} (c31);
\path (r3) edge node {} (c32);

\path (c11) edge node {} (c111);
\path (c11) edge node {} (c112);
\path (c12) edge node {} (c121);
\path (c12) edge node {} (c122);

\path (c21) edge node {} (c211);
\path (c21) edge node {} (c212);
\path (c22) edge node {} (c221);
\path (c22) edge node {} (c222);

\path (c31) edge node {} (c311);
\path (c31) edge node {} (c312);
\path (c32) edge node {} (c321);
\path (c32) edge node {} (c322);

\path (ghost1) edge node {} (d1);
\path (ghost1) edge node {} (d2);
\path (ghost2) edge node {} (d3);
\path (ghost2) edge node {} (d4);
\path (ghost3) edge node {} (d6);

\node (ar1) [above right = 10pt and 0.77cm of r1] {};
\node (ar2) [above right = 10pt and 1.95cm of r1] {};
\node (ar3) [above right = 10pt and 3.47cm of r1] {};
\node (ar4) [above right = 10pt and 4.65cm of r1] {};

\path (ar2) edge node {} (ar1);
\path (ar4) edge node {} (ar3);



\end{tikzpicture}
\caption{Each day, a Merkle tree is constructed using that day's published documents $d_1,d_2,\dots, d_k$. The root of this tree is then hashed along with the hash value of the previous day, and the output value is broadcast along with the published documents. The result is a monitorable hash list $[B_1,B_2,\dots]$.}
\label{fig-merkle-chain}
\end{figure}



\medskip
\noindent{\bf Increasing credibility.} Of course, the solution we just proposed suffers from a similar issue as just publishing government data without the additional hash list and the Merkle trees. Namely, if no one monitors and keeps track of the hash list or Merkle trees, the government is free to change the data, recompute the new Merkle trees and the hash list, and publish them as if they were the original ones. Similarly, if someone does possess a single document they wish to show was changed, even if they have the Merkle tree for that day, it would still be a dispute between the government (claiming that the data that is presently published is the correct one) and the document holder, so it could be difficult to decide whose claim is the actual truth.

A rather simple solution to this problem is to involve into this process non-profit organizations that wish to monitor how transparent is the government in their data publishing practices. More precisely, such organizations would guard some degree of the meta information published by the government, and periodically download the government's documents for some particular day, compute their hash values, and check that the Merkle tree obtained in this way matches the one published by the government. In particular, once that the government publicly announces its schema for publishing the data and additional security certificates (Merkle trees and hash lists) it would be simple to build an automated tool that helps organizations that wish to verify government's data to do so. Depending on  the organization's capacity, the tool could provide various levels of storage and verification requirements. In particular, the tool would support:
\begin{itemize}
\item Storing only the top level hash list of Merkle roots from the solution proposed in Figure \ref{fig-merkle-chain}. This is a very lightweight solution that can be supported even on mobile devices, as it requires storing only two hash values per day. Using this information, a day's data can be verified for modifications at a later date by downloading and hashing it. We can also detect whether the data on any day previous to this one has been modified.
\item Storing the entire Merkle tree, plus the top level hash list of Merkle roots. As explained above, apart from allowing to detect whether the data of some particular day has been modified, this also allows us to  tracing which documents suffered changes.
\item A hybrid solution storing the Merkle tree up to some level, allowing less granularity than storing the entire tree.
\item In terms of verification, the tool would provide support to verify the data of a particular day by downloading it, hashing it, and check that the resulting Merkle tree is correct. Additionally, the tool could verify backwards compatibility by also following the hashes of previous day's data, and checking that they match (for a certain period or the entire history).
\end{itemize}

Note that in terms of storage, none of these solutions would be very expensive, and can in a sense serve as guarantors of the published data on government's pages. Additionally, if the amount of these organizations is sufficiently large, and in particular if they are dispersed around the globe or are untraceable, it becomes unfeasible for a malignant agent to subvert all of their data. Furthermore, the fact that the lightest level of this solution could even be stored on smartphones or dedicated devices, makes it possible for interested individuals to guard the security certificates and check their veracity later, or effectively detect malicious guarantors.